{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0b86a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "tf1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a9af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Dropout, Reshape \n",
    "from tensorflow.keras.layers import Bidirectional, concatenate, BatchNormalization, ZeroPadding1D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "from tensorflow.python.keras.layers import Layer, InputSpec\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Activation, Add, Bidirectional, Conv1D, Dense, Dropout, Embedding, Flatten, Reshape, multiply\n",
    "from keras.layers import concatenate, GRU, Input, LSTM, MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D,  GlobalMaxPooling1D, SpatialDropout1D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d66eaf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py    \n",
    "import numpy as np\n",
    "\n",
    "file_name = r'./cscn/scsn_p_2000_2017_6sec_0.5r_fm_train.hdf5'\n",
    "f1 = h5py.File(file_name,'r')   \n",
    "x = np.array(f1['X'])\n",
    "y = np.array(f1['Y'])\n",
    "x = np.reshape(x,(x.shape[0],x.shape[1],1))\n",
    "ylab = tf.keras.utils.to_categorical(y,num_classes=3)\n",
    "\n",
    "file_name = r'./cscn/scsn_p_2000_2017_6sec_0.5r_fm_test.hdf5'\n",
    "f2 = h5py.File(file_name,'r') \n",
    "xvalid = np.array(f2['X'])\n",
    "yvalid = np.array(f2['Y'])\n",
    "xvalid = np.reshape(xvalid,(xvalid.shape[0],xvalid.shape[1],1))\n",
    "yvalidlab = tf.keras.utils.to_categorical(yvalid,num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc87308",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.load('Training_ind_Polarity.npy')\n",
    "x = x[ind]\n",
    "y = y[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e4a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind0 = np.where(y==0)[0]\n",
    "ind1 = np.where(y==1)[0]\n",
    "ind = np.concatenate([ind0,ind1])\n",
    "\n",
    "x = x[ind]\n",
    "y = y[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c231ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind0 = np.where(yvalid==0)[0]\n",
    "ind1 = np.where(yvalid==1)[0]\n",
    "ind = np.concatenate([ind0,ind1])\n",
    "\n",
    "xvalid = xvalid[ind]\n",
    "yvalid = yvalid[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3a9cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((863151, 600, 1), (1662796, 600, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(xvalid), np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096bd3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "Y\n",
      "dist\n",
      "evids\n",
      "mag\n",
      "sncls\n",
      "snr\n"
     ]
    }
   ],
   "source": [
    "for i in f1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc30e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        #x = layers.Dense(units, activation='relu')(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0984909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rate = 0.2\n",
    "stochastic_depth_rate = 0.1\n",
    "\n",
    "w1 = 100\n",
    "\n",
    "positional_emb = False\n",
    "conv_layers = 2\n",
    "num_classes = 1\n",
    "input_shape = (600,1)\n",
    "image_size = 600  # We'll resize input images to this size\n",
    "projection_dim = int(2*w1)\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0c1e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class CCTTokenizer1(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size=4,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        pooling_kernel_size=3,\n",
    "        pooling_stride=(2,2,2,2,2,2,2,2),\n",
    "        num_conv_layers=conv_layers,\n",
    "        num_output_channels=[int(projection_dim), int(projection_dim), int(projection_dim), int(projection_dim), int(projection_dim), int(projection_dim), int(projection_dim), int(projection_dim)],\n",
    "        positional_emb=positional_emb,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CCTTokenizer1, self).__init__(**kwargs)\n",
    "\n",
    "        # This is our tokenizer.\n",
    "        self.conv_model = tf.keras.Sequential()\n",
    "        for i in range(num_conv_layers):\n",
    "            self.conv_model.add(\n",
    "                layers.Conv1D(\n",
    "                    num_output_channels[i],\n",
    "                    kernel_size,\n",
    "                    stride,\n",
    "                    padding=\"same\",\n",
    "                    use_bias=False,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                )\n",
    "            )\n",
    "            #self.conv_model.add(layers.ZeroPadding2D(padding))\n",
    "            self.conv_model.add(\n",
    "                layers.MaxPool1D(pooling_kernel_size, (pooling_stride[i]), \"same\")\n",
    "            )\n",
    "\n",
    "        self.positional_emb = positional_emb\n",
    "\n",
    "    def call(self, images):\n",
    "        outputs = self.conv_model(images)\n",
    "        # After passing the images through our mini-network the spatial dimensions\n",
    "        # are flattened to form sequences.\n",
    "        reshaped = tf.reshape(\n",
    "            outputs,\n",
    "            (-1, tf.shape(outputs)[1], tf.shape(outputs)[-1]),\n",
    "        )\n",
    "        return reshaped\n",
    "\n",
    "    def positional_embedding(self, image_size):\n",
    "        # Positional embeddings are optional in CCT. Here, we calculate\n",
    "        # the number of sequences and initialize an `Embedding` layer to\n",
    "        # compute the positional embeddings later.\n",
    "        if self.positional_emb:\n",
    "            dummy_inputs = tf.ones((1, image_size, 1))\n",
    "            dummy_outputs = self.call(dummy_inputs)\n",
    "            sequence_length = dummy_outputs.shape[1]\n",
    "            projection_dim = dummy_outputs.shape[-1]\n",
    "\n",
    "            print(dummy_outputs,sequence_length,projection_dim)\n",
    "            embed_layer = layers.Embedding(\n",
    "                input_dim=sequence_length, output_dim=projection_dim\n",
    "            )\n",
    "            return embed_layer, sequence_length\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f21df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referred from: github.com:rwightman/pytorch-image-models.\n",
    "class StochasticDepth(layers.Layer):\n",
    "    def __init__(self, drop_prop, **kwargs):\n",
    "        super(StochasticDepth, self).__init__(**kwargs)\n",
    "        self.drop_prob = drop_prop\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "106152fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_vit_classifier(inputs):\n",
    "def create_cct_model1(inputs):\n",
    "\n",
    "\n",
    "    # Augment data.\n",
    "    #augmented = data_augmentation(inputs)\n",
    "\n",
    "    # Encode patches.\n",
    "    cct_tokenizer = CCTTokenizer1()\n",
    "    encoded_patches = cct_tokenizer(inputs)\n",
    "\n",
    "    # Apply positional embedding.\n",
    "    if positional_emb:\n",
    "        pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
    "        positions = tf.range(start=0, limit=seq_length, delta=1)\n",
    "        position_embeddings = pos_embed(positions)\n",
    "        encoded_patches += position_embeddings\n",
    "\n",
    "    # Calculate Stochastic Depth probabilities.\n",
    "    dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for i in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.2\n",
    "        )(x1, x1)\n",
    "\n",
    "        #print(encoded_patches)\n",
    "        # Skip connection 1.\n",
    "        attention_output = StochasticDepth(dpr[i])(attention_output)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-5)(x2)\n",
    "        #x3 = x2\n",
    "        \n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.2)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        #print(x3)\n",
    "        x3 = StochasticDepth(dpr[i])(x3)\n",
    "        #print(x3)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "     \n",
    "    # Apply sequence pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "    \n",
    "    ''' \n",
    "    attention_weights = tf.nn.softmax(layers.Dense(1)(representation), axis=1)\n",
    "    weighted_representation = tf.matmul(\n",
    "        attention_weights, representation, transpose_a=True\n",
    "    )\n",
    "    weighted_representation = tf.squeeze(weighted_representation, -2)\n",
    "    '''\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11c87b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " cct_tokenizer1 (CCTTokenizer1)  (None, 150, 200)    160800      ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 150, 200)    400         ['cct_tokenizer1[0][0]']         \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 150, 200)    642600      ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " stochastic_depth (StochasticDe  (None, 150, 200)    0           ['multi_head_attention[0][0]']   \n",
      " pth)                                                                                             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 150, 200)     0           ['stochastic_depth[0][0]',       \n",
      "                                                                  'cct_tokenizer1[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 150, 200)    400         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 150, 200)     40200       ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150, 200)     0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 150, 200)     40200       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150, 200)     0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " stochastic_depth_1 (Stochastic  (None, 150, 200)    0           ['dropout_2[0][0]']              \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 150, 200)     0           ['stochastic_depth_1[0][0]',     \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 150, 200)    400         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 150, 200)    642600      ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " stochastic_depth_2 (Stochastic  (None, 150, 200)    0           ['multi_head_attention_1[0][0]'] \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 150, 200)     0           ['stochastic_depth_2[0][0]',     \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 150, 200)    400         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 150, 200)     40200       ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 150, 200)     0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 150, 200)     40200       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 150, 200)     0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " stochastic_depth_3 (Stochastic  (None, 150, 200)    0           ['dropout_5[0][0]']              \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 150, 200)     0           ['stochastic_depth_3[0][0]',     \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 150, 200)    400         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 150, 200)    642600      ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " stochastic_depth_4 (Stochastic  (None, 150, 200)    0           ['multi_head_attention_2[0][0]'] \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 150, 200)     0           ['stochastic_depth_4[0][0]',     \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 150, 200)    400         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 150, 200)     40200       ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 150, 200)     0           ['dense_4[0][0]']                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 150, 200)     40200       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 150, 200)     0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " stochastic_depth_5 (Stochastic  (None, 150, 200)    0           ['dropout_8[0][0]']              \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 150, 200)     0           ['stochastic_depth_5[0][0]',     \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 150, 200)    400         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 150, 200)    642600      ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " stochastic_depth_6 (Stochastic  (None, 150, 200)    0           ['multi_head_attention_3[0][0]'] \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 150, 200)     0           ['stochastic_depth_6[0][0]',     \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 150, 200)    400         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 150, 200)     40200       ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 150, 200)     0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 150, 200)     40200       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 150, 200)     0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " stochastic_depth_7 (Stochastic  (None, 150, 200)    0           ['dropout_11[0][0]']             \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 150, 200)     0           ['stochastic_depth_7[0][0]',     \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 150, 200)    400         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 30000)        0           ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            30001       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,086,401\n",
      "Trainable params: 3,086,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=input_shape,name='input')\n",
    "\n",
    "featuresP = create_cct_model1(inputs)\n",
    "#featuresP = layers.Dropout(0.2)(featuresP)\n",
    "featuresP = layers.Flatten()(featuresP)\n",
    "logitp = layers.Dense(1, activation='sigmoid')(featuresP)\n",
    "\n",
    "\n",
    "#logitp  = Conv2D(1,  3, strides =(1), padding='same',activation='sigmoid', kernel_initializer='he_normal',name='picker_P')(featuresP)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[logitp])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e079848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " cct_tokenizer1_1 (CCTTokenizer  (None, 150, 200)    160800      ['input[0][0]']                  \n",
      " 1)                                                                                               \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 150, 200)    400         ['cct_tokenizer1_1[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 150, 200)    642600      ['layer_normalization_9[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " stochastic_depth_8 (Stochastic  (None, 150, 200)    0           ['multi_head_attention_4[0][0]'] \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 150, 200)     0           ['stochastic_depth_8[0][0]',     \n",
      "                                                                  'cct_tokenizer1_1[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 150, 200)    400         ['add_8[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 150, 200)     40200       ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 150, 200)     0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 150, 200)     40200       ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 150, 200)     0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " stochastic_depth_9 (Stochastic  (None, 150, 200)    0           ['dropout_14[0][0]']             \n",
      " Depth)                                                                                           \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 150, 200)     0           ['stochastic_depth_9[0][0]',     \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 150, 200)    400         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 150, 200)    642600      ['layer_normalization_11[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " stochastic_depth_10 (Stochasti  (None, 150, 200)    0           ['multi_head_attention_5[0][0]'] \n",
      " cDepth)                                                                                          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 150, 200)     0           ['stochastic_depth_10[0][0]',    \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 150, 200)    400         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 150, 200)     40200       ['layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 150, 200)     0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 150, 200)     40200       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 150, 200)     0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " stochastic_depth_11 (Stochasti  (None, 150, 200)    0           ['dropout_17[0][0]']             \n",
      " cDepth)                                                                                          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 150, 200)     0           ['stochastic_depth_11[0][0]',    \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 150, 200)    400         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 150, 200)    642600      ['layer_normalization_13[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " stochastic_depth_12 (Stochasti  (None, 150, 200)    0           ['multi_head_attention_6[0][0]'] \n",
      " cDepth)                                                                                          \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 150, 200)     0           ['stochastic_depth_12[0][0]',    \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 150, 200)    400         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 150, 200)     40200       ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_19 (Dropout)           (None, 150, 200)     0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 150, 200)     40200       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 150, 200)     0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " stochastic_depth_13 (Stochasti  (None, 150, 200)    0           ['dropout_20[0][0]']             \n",
      " cDepth)                                                                                          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 150, 200)     0           ['stochastic_depth_13[0][0]',    \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 150, 200)    400         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 150, 200)    642600      ['layer_normalization_15[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " stochastic_depth_14 (Stochasti  (None, 150, 200)    0           ['multi_head_attention_7[0][0]'] \n",
      " cDepth)                                                                                          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 150, 200)     0           ['stochastic_depth_14[0][0]',    \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 150, 200)    400         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 150, 200)     40200       ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 150, 200)     0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 150, 200)     40200       ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 150, 200)     0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " stochastic_depth_15 (Stochasti  (None, 150, 200)    0           ['dropout_23[0][0]']             \n",
      " cDepth)                                                                                          \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 150, 200)     0           ['stochastic_depth_15[0][0]',    \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 150, 200)    400         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 30000)        0           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 30000)        0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            30001       ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,086,401\n",
      "Trainable params: 3,086,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=input_shape,name='input')\n",
    "\n",
    "featuresP = create_cct_model1(inputs)\n",
    "featuresP = layers.Flatten()(featuresP)\n",
    "featuresP = layers.Dropout(0.2)(featuresP)\n",
    "logitp = layers.Dense(1, activation='sigmoid')(featuresP)\n",
    "\n",
    "\n",
    "#logitp  = Conv2D(1,  3, strides =(1), padding='same',activation='sigmoid', kernel_initializer='he_normal',name='picker_P')(featuresP)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[logitp])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8d5ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='best_weigths_Binary_CSCN.h5',\n",
    "                             monitor='val_acc',\n",
    "                             mode = 'max',\n",
    "                             verbose=1,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=0.1,\n",
    "                                   cooldown=0,\n",
    "                                   patience=50,\n",
    "                                   min_lr=0.5e-6,\n",
    "                                   monitor='val_acc',\n",
    "                                   mode = 'max',\n",
    "                                  verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b0a5dfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1496516 samples, validate on 166280 samples\n",
      "Epoch 1/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1080 - acc: 0.9653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.96226, saving model to best_weigths_Binary_CSCN.h5\n",
      "1496516/1496516 [==============================] - 1647s 1ms/sample - loss: 0.1080 - acc: 0.9653 - val_loss: 0.1140 - val_acc: 0.9623 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1059 - acc: 0.9651\n",
      "Epoch 2: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1633s 1ms/sample - loss: 0.1059 - acc: 0.9651 - val_loss: 0.1434 - val_acc: 0.9454 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1247 - acc: 0.9605\n",
      "Epoch 3: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1631s 1ms/sample - loss: 0.1247 - acc: 0.9605 - val_loss: 0.1807 - val_acc: 0.9413 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1280 - acc: 0.9592\n",
      "Epoch 4: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1629s 1ms/sample - loss: 0.1280 - acc: 0.9592 - val_loss: 0.1197 - val_acc: 0.9589 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1336 - acc: 0.9580\n",
      "Epoch 5: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1627s 1ms/sample - loss: 0.1336 - acc: 0.9580 - val_loss: 0.1564 - val_acc: 0.9374 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1329 - acc: 0.9590\n",
      "Epoch 6: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1626s 1ms/sample - loss: 0.1329 - acc: 0.9590 - val_loss: 0.1627 - val_acc: 0.9476 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1356 - acc: 0.9582\n",
      "Epoch 7: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1622s 1ms/sample - loss: 0.1356 - acc: 0.9582 - val_loss: 0.1793 - val_acc: 0.9394 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1336 - acc: 0.9592\n",
      "Epoch 8: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1623s 1ms/sample - loss: 0.1336 - acc: 0.9592 - val_loss: 0.1621 - val_acc: 0.9470 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1318 - acc: 0.9593\n",
      "Epoch 9: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1621s 1ms/sample - loss: 0.1318 - acc: 0.9593 - val_loss: 0.1630 - val_acc: 0.9436 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1272 - acc: 0.9606\n",
      "Epoch 10: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1620s 1ms/sample - loss: 0.1272 - acc: 0.9606 - val_loss: 0.1662 - val_acc: 0.9470 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1223 - acc: 0.9628\n",
      "Epoch 11: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1620s 1ms/sample - loss: 0.1223 - acc: 0.9628 - val_loss: 0.1382 - val_acc: 0.9548 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1281 - acc: 0.9608\n",
      "Epoch 12: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1620s 1ms/sample - loss: 0.1281 - acc: 0.9608 - val_loss: 0.1325 - val_acc: 0.9534 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1279 - acc: 0.9608\n",
      "Epoch 13: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1621s 1ms/sample - loss: 0.1279 - acc: 0.9608 - val_loss: 0.1463 - val_acc: 0.9532 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 14: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1621s 1ms/sample - loss: 0.1262 - acc: 0.9615 - val_loss: 0.1466 - val_acc: 0.9522 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1224 - acc: 0.9631\n",
      "Epoch 15: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1620s 1ms/sample - loss: 0.1224 - acc: 0.9631 - val_loss: 0.1433 - val_acc: 0.9524 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1178 - acc: 0.9643\n",
      "Epoch 16: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1622s 1ms/sample - loss: 0.1178 - acc: 0.9643 - val_loss: 0.1257 - val_acc: 0.9558 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1146 - acc: 0.9654\n",
      "Epoch 17: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1625s 1ms/sample - loss: 0.1146 - acc: 0.9654 - val_loss: 0.1232 - val_acc: 0.9579 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1117 - acc: 0.9665\n",
      "Epoch 18: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1625s 1ms/sample - loss: 0.1117 - acc: 0.9665 - val_loss: 0.1335 - val_acc: 0.9526 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1095 - acc: 0.9671\n",
      "Epoch 19: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1623s 1ms/sample - loss: 0.1095 - acc: 0.9671 - val_loss: 0.1367 - val_acc: 0.9535 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1077 - acc: 0.9675\n",
      "Epoch 20: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1626s 1ms/sample - loss: 0.1077 - acc: 0.9675 - val_loss: 0.1463 - val_acc: 0.9518 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1054 - acc: 0.9680\n",
      "Epoch 21: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1627s 1ms/sample - loss: 0.1054 - acc: 0.9680 - val_loss: 0.1267 - val_acc: 0.9569 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1041 - acc: 0.9683\n",
      "Epoch 22: val_acc did not improve from 0.96226\n",
      "1496516/1496516 [==============================] - 1629s 1ms/sample - loss: 0.1041 - acc: 0.9683 - val_loss: 0.1098 - val_acc: 0.9605 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.1018 - acc: 0.9689\n",
      "Epoch 23: val_acc improved from 0.96226 to 0.96247, saving model to best_weigths_Binary_CSCN.h5\n",
      "1496516/1496516 [==============================] - 1631s 1ms/sample - loss: 0.1018 - acc: 0.9689 - val_loss: 0.1056 - val_acc: 0.9625 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0992 - acc: 0.9695\n",
      "Epoch 24: val_acc improved from 0.96247 to 0.96415, saving model to best_weigths_Binary_CSCN.h5\n",
      "1496516/1496516 [==============================] - 1631s 1ms/sample - loss: 0.0992 - acc: 0.9695 - val_loss: 0.0998 - val_acc: 0.9642 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0958 - acc: 0.9701\n",
      "Epoch 25: val_acc did not improve from 0.96415\n",
      "1496516/1496516 [==============================] - 1645s 1ms/sample - loss: 0.0958 - acc: 0.9701 - val_loss: 0.1242 - val_acc: 0.9574 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0932 - acc: 0.9706\n",
      "Epoch 26: val_acc improved from 0.96415 to 0.96854, saving model to best_weigths_Binary_CSCN.h5\n",
      "1496516/1496516 [==============================] - 1635s 1ms/sample - loss: 0.0932 - acc: 0.9706 - val_loss: 0.0875 - val_acc: 0.9685 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0908 - acc: 0.9711\n",
      "Epoch 27: val_acc did not improve from 0.96854\n",
      "1496516/1496516 [==============================] - 1637s 1ms/sample - loss: 0.0908 - acc: 0.9711 - val_loss: 0.1082 - val_acc: 0.9626 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0882 - acc: 0.9717\n",
      "Epoch 28: val_acc did not improve from 0.96854\n",
      "1496516/1496516 [==============================] - 1643s 1ms/sample - loss: 0.0882 - acc: 0.9717 - val_loss: 0.1088 - val_acc: 0.9635 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0862 - acc: 0.9723\n",
      "Epoch 29: val_acc did not improve from 0.96854\n",
      "1496516/1496516 [==============================] - 1637s 1ms/sample - loss: 0.0862 - acc: 0.9723 - val_loss: 0.1087 - val_acc: 0.9620 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0845 - acc: 0.9728\n",
      "Epoch 30: val_acc did not improve from 0.96854\n",
      "1496516/1496516 [==============================] - 1644s 1ms/sample - loss: 0.0845 - acc: 0.9728 - val_loss: 0.0973 - val_acc: 0.9642 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0832 - acc: 0.9732\n",
      "Epoch 31: val_acc did not improve from 0.96854\n",
      "1496516/1496516 [==============================] - 1639s 1ms/sample - loss: 0.0832 - acc: 0.9732 - val_loss: 0.0983 - val_acc: 0.9665 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0819 - acc: 0.9735\n",
      "Epoch 32: val_acc improved from 0.96854 to 0.97223, saving model to best_weigths_Binary_CSCN.h5\n",
      "1496516/1496516 [==============================] - 1638s 1ms/sample - loss: 0.0819 - acc: 0.9735 - val_loss: 0.0772 - val_acc: 0.9722 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0808 - acc: 0.9738\n",
      "Epoch 33: val_acc did not improve from 0.97223\n",
      "1496516/1496516 [==============================] - 1644s 1ms/sample - loss: 0.0808 - acc: 0.9738 - val_loss: 0.1156 - val_acc: 0.9608 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0799 - acc: 0.9741\n",
      "Epoch 34: val_acc did not improve from 0.97223\n",
      "1496516/1496516 [==============================] - 1638s 1ms/sample - loss: 0.0799 - acc: 0.9741 - val_loss: 0.0795 - val_acc: 0.9708 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0792 - acc: 0.9743\n",
      "Epoch 35: val_acc did not improve from 0.97223\n",
      "1496516/1496516 [==============================] - 1638s 1ms/sample - loss: 0.0792 - acc: 0.9743 - val_loss: 0.0844 - val_acc: 0.9696 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0785 - acc: 0.9745\n",
      "Epoch 36: val_acc did not improve from 0.97223\n",
      "1496516/1496516 [==============================] - 1638s 1ms/sample - loss: 0.0785 - acc: 0.9745 - val_loss: 0.0905 - val_acc: 0.9691 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1496516/1496516 [==============================] - ETA: 0s - loss: 0.0778 - acc: 0.9748\n",
      "Epoch 37: val_acc did not improve from 0.97223\n",
      "1496516/1496516 [==============================] - 1637s 1ms/sample - loss: 0.0778 - acc: 0.9748 - val_loss: 0.0870 - val_acc: 0.9684 - lr: 0.0010\n",
      "Epoch 38/500\n",
      " 162176/1496516 [==>...........................] - ETA: 23:35 - loss: 0.0784 - acc: 0.9743"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21370/201447765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     return fit_loop(\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4282\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4284\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   4285\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   4286\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sp = 0.9\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=['binary_crossentropy'], metrics=['acc'])\n",
    "model.fit(x, y, batch_size=128, epochs=500, verbose =1, validation_split=0.1, shuffle=True, callbacks=[checkpoint,lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6790c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 01:12:31.412455: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-30 01:12:32.014457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9275 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n",
      "2022-10-30 01:12:32.090040: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('best_weigths_Binary_CSCN.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab17a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-10-30 01:12:35.563641: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2022-10-30 01:12:36.197392: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2022-10-30 01:12:36.244265: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "out = model.predict(xvalid,batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bcd5151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9787545863933426,\n",
       " 0.9787545863933426,\n",
       " 0.9787545863933426,\n",
       " 0.9787545863933426)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "#outtest = np.argmax(out,axis=-1)\n",
    "thre = 0.5\n",
    "outtest = out\n",
    "outtest[outtest<thre]=0\n",
    "outtest[outtest>=thre]=1\n",
    "labtest = yvalid\n",
    "\n",
    "accuracy_score(labtest,outtest),precision_score(labtest,outtest, average='micro'),recall_score(labtest,outtest, average='micro'),f1_score(labtest,outtest, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "080f4853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9787545863933426,\n",
       " array([0.99068385, 0.95451592]),\n",
       " array([0.97790341, 0.98055446]),\n",
       " array([0.98425214, 0.96736   ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labtest,outtest),precision_score(labtest,outtest, average=None),recall_score(labtest,outtest, average=None),f1_score(labtest,outtest, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d130f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[573069  12949]\n",
      " [  5389 271744]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Generate the confusion matrix\n",
    "cf_matrix = confusion_matrix(labtest, outtest)\n",
    "\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d0df677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 16}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "cf = cf_matrix\n",
    "categories=['Up','Down']\n",
    "group_percentages = []\n",
    "counts = []\n",
    "for i in range(len(cf)):\n",
    "    for j in range(len(cf)):\n",
    "        group_percentages.append(cf[j, i]/np.sum(cf[:, i]))\n",
    "        counts.append(cf[j, i])\n",
    "\n",
    "percentages_matrix = np.reshape(group_percentages, (2, 2))\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in group_percentages]\n",
    "\n",
    "labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_percentages, counts)]\n",
    "labels = np.asarray(labels).reshape(2, 2, order = 'F')\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=2) # for label size\n",
    "sn.heatmap(percentages_matrix, annot = labels, fmt = '', xticklabels=categories, yticklabels = categories, cbar = False)\n",
    "#fig.savefig('Conf_Matrix',bbox_inches='tight',transparent=True, dpi =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562247d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08184de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-39",
   "language": "python",
   "name": "tf-gpu-39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
